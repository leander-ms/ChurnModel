Epoch,Training Loss,Validation Loss
0,0.11568731814622879,0.10342931002378464
1,0.10351254045963287,0.10273241251707077
2,0.10256270319223404,0.1020781546831131
3,0.10210143774747849,0.10215478390455246
4,0.10170207172632217,0.10175827145576477
5,0.1016782596707344,0.10187055915594101
6,0.10127530246973038,0.10172272473573685
7,0.10124509781599045,0.10169932246208191
8,0.10118173062801361,0.10174132883548737
9,0.1009979397058487,0.10172992944717407
10,0.10096606612205505,0.10181578248739243
11,0.10099765658378601,0.10187286883592606
12,0.10093359649181366,0.10194077342748642
13,0.1009092777967453,0.10176151245832443
14,0.10086921602487564,0.10152484476566315
15,0.10088237375020981,0.10190973430871964
16,0.10088033974170685,0.10167324542999268
17,0.10083083808422089,0.10175195336341858
18,0.10075722634792328,0.10177455842494965
19,0.1007758229970932,0.10204797983169556
20,0.10083630681037903,0.10162252932786942
21,0.10073408484458923,0.10220949351787567
22,0.10080516338348389,0.10165870934724808
23,0.10071603208780289,0.1016329973936081
24,0.10072944313287735,0.10188034921884537
25,0.1007792204618454,0.10183806717395782
26,0.10078714042901993,0.10201747715473175
27,0.10076572000980377,0.1015365794301033
28,0.10071060806512833,0.10169752687215805
29,0.10073836147785187,0.10155067592859268
